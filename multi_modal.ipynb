{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNI639BA1xGE3m6reMTeas",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dev-nileshpawar/python-aiml/blob/main/multi_modal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabula\n",
        "!pip install boto3\n",
        "!pip install faiss-cpu\n",
        "!pip install pymupdf\n",
        "!pip install langchain_text_splitters\n",
        "!pip install langchain\n",
        "!pip install tabula-py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS494pStzhy7",
        "outputId": "d465e8db-7430-45c0-b15f-d800747ba700"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabula in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tabula) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tabula) (2.3.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (1.41.5)\n",
            "Requirement already satisfied: botocore<1.42.0,>=1.41.5 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.41.5)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.16.0,>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from boto3) (0.15.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.42.0,>=1.41.5->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.42.0,>=1.41.5->boto3) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.42.0,>=1.41.5->boto3) (1.17.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.6)\n",
            "Requirement already satisfied: langchain_text_splitters in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_text_splitters) (1.1.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.4.47)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (4.15.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (1.3.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.47)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
            "Requirement already satisfied: tabula-py in /usr/local/lib/python3.12/dist-packages (2.10.0)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.12/dist-packages (from tabula-py) (2.2.2)\n",
            "Requirement already satisfied: numpy>1.24.4 in /usr/local/lib/python3.12/dist-packages (from tabula-py) (2.3.5)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.12/dist-packages (from tabula-py) (1.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "7xuzdYxozaS7"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import tabula\n",
        "import faiss\n",
        "import json\n",
        "import base64\n",
        "import pymupdf\n",
        "import requests\n",
        "import os\n",
        "import logging\n",
        "import numpy as np\n",
        "# import warning\n",
        "from tqdm import tqdm\n",
        "from botocore.exceptions import ClientError\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from IPython import display\n",
        "\n",
        "# logger = logging.getLogger(__name__)\n",
        "# logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://arxiv.org/pdf/1706.03760\"\n",
        "response = requests.get(url)\n",
        "filename = \"attention_paper.pdf\"\n",
        "filepath = os.path.join(\"data\", filename)\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "with open(filepath, \"wb\") as f:\n",
        "  if response.status_code==200:\n",
        "    f.write(response.content)\n",
        "    print(f\"File downloaded successfully: {filepath}\")\n",
        "  else:\n",
        "    print(f\"Failed to download file. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODwdvSs_zfvM",
        "outputId": "b864a9de-b429-4b40-f598-5c8ea6c6e79d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully: data/attention_paper.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S45dENXKzsdU"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data extractio"
      ],
      "metadata": {
        "id": "Rt4DRS9F0bcx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CMS4MFzm0cKM"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Multi modal RAG with Amazon Bedrock, Amazon Nova and LangChain</h1>\n"
      ],
      "metadata": {
        "id": "cA81zMSZ0gn6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DAn_b-i00g_W"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\"><b>Customize a Foundation Model</b></h1>\n",
        "### 1. Instruction-based Fine-Tuning\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  +------------------------------+\n",
        "  | Task-Specific Labeled Data   |\n",
        "  +------------------------------+\n",
        "                |\n",
        "                v   Fine-Tuning\n",
        "                |\n",
        "                v\n",
        "  +------------------------------+\n",
        "  |            LLM               | <---------------------- User/System Prompt\n",
        "  +------------------------------+\n",
        "```\n",
        "\n",
        "\n",
        "### 2. Domain adoption\n",
        "```\n",
        "  +--------------------------------+\n",
        "  | Domain specific unlebeled data |\n",
        "  +--------------------------------+\n",
        "                   |\n",
        "                   v  Continious pre training\n",
        "                   |\n",
        "                   v\n",
        "  +--------------------------------+\n",
        "  |            LLM                 |<----------------user/system prompts\n",
        "  +--------------------------------+\n",
        "```\n",
        "\n",
        "\n",
        "### 3. Informative Retrieval\n",
        "1. convert knowledge data (Audio, video, Image, Text) into embeddings and store vectors into vector DB\n",
        "2. whenever user sends a query then we search into vector DB for relevant info (data chunk)\n",
        "3. we call LLM by passing relavant info chunk and user query and extract final answer.\n",
        "\n",
        "```\n",
        "    +-----------------------------------+\n",
        "    |  Domain specific unlabeled data   |\n",
        "    +-----------------------------------+\n",
        "                     |   Embeddings\n",
        "                     V   \n",
        "                     |   prompt\n",
        "                     v\n",
        "                     |   Prompt with context\n",
        "                     v\n",
        "       +---------------------------+\n",
        "       |           LLM             |\n",
        "       +---------------------------+\n",
        "```\n"
      ],
      "metadata": {
        "id": "ZLt0aKmV0jbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wrapper function to extract the data from file\n",
        "\n",
        "def create_directories(base_path):\n",
        "  directories = [\"images\", \"text\", \"tables\", \"page_images\"]\n",
        "  for dir in directories:\n",
        "    if not os.path.exists(os.path.join(base_path, dir)):\n",
        "      os.makedirs(os.path.join(base_path, dir))\n",
        "\n",
        "def process_tables(doc, page_num, base_dir, items):\n",
        "  try:\n",
        "    tables = tabula.read_pdf(filepath, pages = page_num+1, multiple_tables=True)\n",
        "    # print(tables)\n",
        "    for table_id, table in enumerate(tables):\n",
        "      table_text = \"\\n\".join([\" | \".join(map(str, row)) for row in table.values])\n",
        "      table_file_name = f\"{base_dir}/tables/{os.path.basename(filepath)}_table_{page_num}_{table_id}.txt\"\n",
        "\n",
        "      with open(table_file_name, \"w\") as f:\n",
        "        f.write(table_text)\n",
        "        items.append({\"page\": page_num, \"type\":\"table\", \"text\": table_text, \"path\": table_file_name})\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return\n",
        "def process_text_chunks(text, text_splitter, page_num, base_dir, items):\n",
        "  text_chunks = text_splitter.split_text(text)\n",
        "  for chunk_id, chunk in enumerate(text_chunks):\n",
        "    text_file_name = f\"{base_dir}/text/{os.path.basename(filepath)}_text_{page_num}_{chunk_id}.txt\"\n",
        "    with open(text_file_name, \"w\") as f:\n",
        "      f.write(chunk)\n",
        "      items.append({\"page\": page_num, \"type\": \"text\", \"text\": chunk, \"path\": text_file_name})\n",
        "  return\n",
        "def process_images(page, page_num, base_dir, items):\n",
        "  image_list = page.get_images()\n",
        "  for image_id, image in enumerate(image_list):\n",
        "    xref = image[0]\n",
        "    pix = pymupdf.Pixmap(doc, xref)\n",
        "    image_file_name = f\"{base_dir}/images/{os.path.basename(filepath)}_image_{page_num}_{image_id}_{xref}.png\"\n",
        "    pix.save(image_file_name)\n",
        "    with open(image_file_name, \"rb\") as f:\n",
        "      image_bytes = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "    items.append({\"page\": page_num, \"type\": \"image\", \"path\":image_id, \"image\": image_bytes})\n",
        "  return\n",
        "def process_page_images(page, page_num, base_dir, items):\n",
        "  return"
      ],
      "metadata": {
        "id": "bUPlGZ1O0j5b"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = pymupdf.open(filepath)\n",
        "num_pages = len(doc)\n",
        "base_dir = \"data\"\n",
        "\n",
        "create_directories(base_dir)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "items = []\n",
        "\n",
        "# process each page of the pdf\n",
        "for page_num in tqdm(range(num_pages)):\n",
        "  page = doc.load_page(page_num)\n",
        "  text = page.get_text(\"text\")\n",
        "  process_tables(doc, page_num, base_dir, items)\n",
        "  process_text_chunks(text, text_splitter, page_num, base_dir, items)\n",
        "  process_images(page, page_num, base_dir, items)\n",
        "  process_page_images(page, page_num, base_dir, items)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxSmJZK60wNN",
        "outputId": "341b9c4a-4623-4ebb-af96-d55349466efa"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]WARNING:tabula.backend:Got stderr: Nov 29, 2025 1:15:40 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Nov 29, 2025 1:15:40 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "\n",
            " 10%|█         | 1/10 [00:06<01:01,  6.85s/it]WARNING:tabula.backend:Got stderr: Nov 29, 2025 1:15:50 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Nov 29, 2025 1:15:50 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Nov 29, 2025 1:15:50 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketleft (104) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:15:50 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketright (105) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:15:50 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraldisplay (90) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:15:50 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationdisplay (88) in font KCJOOH+CMEX10\n",
            "\n",
            " 20%|██        | 2/10 [00:16<01:06,  8.25s/it]WARNING:tabula.backend:Got stderr: Nov 29, 2025 1:15:56 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Nov 29, 2025 1:15:56 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Nov 29, 2025 1:15:56 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for negationslash (54) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:15:56 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraldisplay (90) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:15:56 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationdisplay (88) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:15:56 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraltext (82) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:15:56 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for rho1 (37) in font LKWMPD+CMMI10\n",
            "\n",
            " 30%|███       | 3/10 [00:20<00:44,  6.31s/it]WARNING:tabula.backend:Got stderr: Nov 29, 2025 1:16:01 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Nov 29, 2025 1:16:01 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for rho1 (37) in font LKWMPD+CMMI10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraldisplay (90) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketleftbig (2) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketrightbig (3) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketright (105) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketleft (104) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraltext (82) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "SEVERE: Can't read the embedded Type1 font WVOVMN+BBOLD10\n",
            "java.io.IOException: Found Token[kind=LITERAL, text=UnderlineThickness] but expected NAME\n",
            "\tat org.apache.fontbox.type1.Type1Parser.read(Type1Parser.java:853)\n",
            "\tat org.apache.fontbox.type1.Type1Parser.read(Type1Parser.java:864)\n",
            "\tat org.apache.fontbox.type1.Type1Parser.readSimpleDict(Type1Parser.java:353)\n",
            "\tat org.apache.fontbox.type1.Type1Parser.parseASCII(Type1Parser.java:127)\n",
            "\tat org.apache.fontbox.type1.Type1Parser.parse(Type1Parser.java:61)\n",
            "\tat org.apache.fontbox.type1.Type1Font.createWithSegments(Type1Font.java:85)\n",
            "\tat org.apache.pdfbox.pdmodel.font.PDType1Font.<init>(PDType1Font.java:263)\n",
            "\tat org.apache.pdfbox.pdmodel.font.PDFontFactory.createFont(PDFontFactory.java:76)\n",
            "\tat org.apache.pdfbox.pdmodel.PDResources.getFont(PDResources.java:146)\n",
            "\tat org.apache.pdfbox.contentstream.operator.text.SetFontAndSize.process(SetFontAndSize.java:66)\n",
            "\tat org.apache.pdfbox.contentstream.PDFStreamEngine.processOperator(PDFStreamEngine.java:933)\n",
            "\tat org.apache.pdfbox.contentstream.PDFStreamEngine.processStreamOperators(PDFStreamEngine.java:514)\n",
            "\tat org.apache.pdfbox.contentstream.PDFStreamEngine.processStream(PDFStreamEngine.java:492)\n",
            "\tat org.apache.pdfbox.contentstream.PDFStreamEngine.processPage(PDFStreamEngine.java:155)\n",
            "\tat technology.tabula.ObjectExtractor.extractPage(ObjectExtractor.java:24)\n",
            "\tat technology.tabula.PageIterator.next(PageIterator.java:30)\n",
            "\tat technology.tabula.CommandLineApp.extractFile(CommandLineApp.java:161)\n",
            "\tat technology.tabula.CommandLineApp.extractFileTables(CommandLineApp.java:124)\n",
            "\tat technology.tabula.CommandLineApp.extractTables(CommandLineApp.java:106)\n",
            "\tat technology.tabula.CommandLineApp.main(CommandLineApp.java:76)\n",
            "\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans-Bold for WVOVMN+BBOLD10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for vector (126) in font ZEVGLZ+CMMI9\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketright (105) in font WMACWA+CMSY9\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for vector (126) in font LKWMPD+CMMI10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketleftBig (104) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketrightBig (105) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:02 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:07 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "SEVERE: Can't read the embedded Type1 font WVOVMN+BBOLD10\n",
            "java.io.IOException: Found Token[kind=LITERAL, text=UnderlineThickness] but expected NAME\n",
            "\tat org.apache.fontbox.type1.Type1Parser.read(Type1Parser.java:853)\n",
            "\tat org.apache.fontbox.type1.Type1Parser.read(Type1Parser.java:864)\n",
            "\tat org.apache.fontbox.type1.Type1Parser.readSimpleDict(Type1Parser.java:353)\n",
            "\tat org.apache.fontbox.type1.Type1Parser.parseASCII(Type1Parser.java:127)\n",
            "\tat org.apache.fontbox.type1.Type1Parser.parse(Type1Parser.java:61)\n",
            "\tat org.apache.fontbox.type1.Type1Font.createWithSegments(Type1Font.java:85)\n",
            "\tat org.apache.pdfbox.pdmodel.font.PDType1Font.<init>(PDType1Font.java:263)\n",
            "\tat org.apache.pdfbox.pdmodel.font.PDFontFactory.createFont(PDFontFactory.java:76)\n",
            "\tat org.apache.pdfbox.pdmodel.PDResources.getFont(PDResources.java:146)\n",
            "\tat org.apache.pdfbox.contentstream.operator.text.SetFontAndSize.process(SetFontAndSize.java:66)\n",
            "\tat org.apache.pdfbox.contentstream.PDFStreamEngine.processOperator(PDFStreamEngine.java:933)\n",
            "\tat org.apache.pdfbox.contentstream.PDFStreamEngine.processStreamOperators(PDFStreamEngine.java:514)\n",
            "\tat org.apache.pdfbox.contentstream.PDFStreamEngine.processStream(PDFStreamEngine.java:492)\n",
            "\tat org.apache.pdfbox.contentstream.PDFStreamEngine.processPage(PDFStreamEngine.java:155)\n",
            "\tat org.apache.pdfbox.rendering.PageDrawer.drawPage(PageDrawer.java:277)\n",
            "\tat org.apache.pdfbox.rendering.PDFRenderer.renderImage(PDFRenderer.java:347)\n",
            "\tat org.apache.pdfbox.rendering.PDFRenderer.renderImage(PDFRenderer.java:268)\n",
            "\tat org.apache.pdfbox.rendering.PDFRenderer.renderImageWithDPI(PDFRenderer.java:254)\n",
            "\tat technology.tabula.Utils.pageConvertToImage(Utils.java:285)\n",
            "\tat technology.tabula.detectors.NurminenDetectionAlgorithm.detect(NurminenDetectionAlgorithm.java:113)\n",
            "\tat technology.tabula.CommandLineApp$TableExtractor.extractTablesBasic(CommandLineApp.java:421)\n",
            "\tat technology.tabula.CommandLineApp$TableExtractor.extractTables(CommandLineApp.java:408)\n",
            "\tat technology.tabula.CommandLineApp.extractFile(CommandLineApp.java:180)\n",
            "\tat technology.tabula.CommandLineApp.extractFileTables(CommandLineApp.java:124)\n",
            "\tat technology.tabula.CommandLineApp.extractTables(CommandLineApp.java:106)\n",
            "\tat technology.tabula.CommandLineApp.main(CommandLineApp.java:76)\n",
            "\n",
            "Nov 29, 2025 1:16:07 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans-Bold for WVOVMN+BBOLD10\n",
            "\n",
            " 40%|████      | 4/10 [00:31<00:48,  8.14s/it]WARNING:tabula.backend:Got stderr: Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for vector (126) in font LKWMPD+CMMI10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketright (105) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketright (105) in font ZVBECL+CMSY7\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketleft (104) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenleftbigg (18) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenrightbigg (19) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for squaresolid (4) in font FFXOED+MSAM10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for diamondsolid (7) in font FFXOED+MSAM10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for triangledownsld (72) in font FFXOED+MSAM10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for trianglesolid (78) in font FFXOED+MSAM10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for rho1 (37) in font LKWMPD+CMMI10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraldisplay (90) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for rho1 (37) in font ZBUAWM+CMMI7\n",
            "\n",
            " 50%|█████     | 5/10 [00:47<00:56, 11.27s/it]WARNING:tabula.backend:Got stderr: Nov 29, 2025 1:16:31 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Nov 29, 2025 1:16:31 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for 2 (34) in font LKREMM+CambriaMath\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for 3 (35) in font LKREMM+CambriaMath\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for rho1 (37) in font ZEVGLZ+CMMI9\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketright (105) in font WMACWA+CMSY9\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketleft (104) in font WMACWA+CMSY9\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketright (105) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for rho1 (37) in font LKWMPD+CMMI10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraltext (82) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketleft (104) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for prime (48) in font ZVBECL+CMSY7\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenleftbig (0) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraldisplay (90) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for vextendsingle (12) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketrightbigg (29) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketleftbigg (28) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketrightbig (11) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenleftbigg (18) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenrightbigg (19) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:37 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for 2 (34) in font LKREMM+CambriaMath\n",
            "Nov 29, 2025 1:16:37 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for 3 (35) in font LKREMM+CambriaMath\n",
            "\n",
            " 60%|██████    | 6/10 [00:59<00:45, 11.30s/it]WARNING:tabula.backend:Got stderr: Nov 29, 2025 1:16:39 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Nov 29, 2025 1:16:39 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Nov 29, 2025 1:16:39 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketright (105) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:16:39 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketleft (104) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:16:39 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketleftBig (104) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:39 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenleftBig (16) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:39 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenrightBig (17) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:39 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketrightBig (105) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:39 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraldisplay (90) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:39 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationdisplay (88) in font KCJOOH+CMEX10\n",
            "\n",
            " 70%|███████   | 7/10 [01:02<00:26,  8.73s/it]WARNING:tabula.backend:Got stderr: Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationdisplay (88) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for negationslash (54) in font ZVBECL+CMSY7\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenleftbig (0) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenrightbig (1) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketleftbigg (20) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketrightbigg (21) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenleftbigg (18) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenrightbigg (19) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketright (105) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for angbracketleft (104) in font NSFHZE+CMSY10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for vector (126) in font LKWMPD+CMMI10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketleftBig (104) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketrightBig (105) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenleftBig (16) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for parenrightBig (17) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraldisplay (90) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketleftbig (2) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for bracketrightbig (3) in font KCJOOH+CMEX10\n",
            "Nov 29, 2025 1:16:43 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for integraltext (82) in font KCJOOH+CMEX10\n",
            "\n",
            " 80%|████████  | 8/10 [01:07<00:15,  7.59s/it]WARNING:tabula.backend:Got stderr: Nov 29, 2025 1:16:47 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Nov 29, 2025 1:16:47 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "\n",
            " 90%|█████████ | 9/10 [01:11<00:06,  6.36s/it]WARNING:tabula.backend:Got stderr: Nov 29, 2025 1:16:51 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Nov 29, 2025 1:16:51 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "\n",
            "100%|██████████| 10/10 [01:13<00:00,  7.36s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_multimodal_embedding(prompt=None, image=None, output_embedding_length=384):\n",
        "  if not prompt and not image:\n",
        "    raise ValueError(\"prompt or image must be provided\")\n",
        "\n",
        "  model_id = \"amazon.titan-embed-image-v1\"\n",
        "  body = {\"embeddingConfig\": {\"outputEmbeddingLength\": output_embedding_length}}\n",
        "\n",
        "  if prompt:\n",
        "    body[\"inputText\"] = prompt\n",
        "  if image:\n",
        "    body[\"inputImage\"] = image\n",
        "\n",
        "  try:\n",
        "    response = client.invoke_model(\n",
        "        body=json.dumps(body),\n",
        "        modelId=model_id,\n",
        "        accept=\"application/json\",\n",
        "        contentType=\"application/json\"\n",
        "    )\n",
        "    response_body = json.loads(response.get(\"body\").read())\n",
        "    embedding = response_body[\"embedding\"]\n",
        "    return embedding\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "5RlVwTSz0yem"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "PRO_MODEL_ID = \"amazon.nova-pro-v1:0\"\n",
        "LITE_MODEL_ID = \"amazon.nova-lite-v1:0\"\n",
        "MACRO_MODEL_ID = \"amazon.nova-macro-v1:0\"\n",
        "\n",
        "YOUR_ACCESS_KEY = userdata.get('YOUR_ACCESS_KEY')\n",
        "YOUR_SECRET_KEY = userdata.get(\"YOUR_SECRET_KEY\")\n",
        "print(\"--------\", YOUR_ACCESS_KEY)\n",
        "print(\"--------\", YOUR_SECRET_KEY)\n",
        "client = boto3.client(\n",
        "    service_name=\"bedrock-runtime\",\n",
        "    region_name=\"us-east-1\",\n",
        "    aws_access_key_id=YOUR_ACCESS_KEY,\n",
        "    aws_secret_access_key=YOUR_SECRET_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "N5O0H3Bv05Wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee9ed10-ae8f-447c-f29c-66c8832231a1"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------- AKIAQMHLVHQ566HGWXEK\n",
            "-------- UAjRcLLTkSr838zLGY161PM+lqrpftasnt0dh93h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_dimension = 384\n",
        "\n",
        "item_counts = {\n",
        "  \"text\": sum(1 for item in items if item[\"type\"] == \"text\"),\n",
        "  \"table\": sum(1 for item in items if item[\"type\"] == \"table\"),\n",
        "  \"image\": sum(1 for item in items if item[\"type\"] == \"image\"),\n",
        "  \"page\": sum(1 for item in items if item[\"type\"] == \"page\")\n",
        "}\n",
        "\n",
        "counters = dict.fromkeys(item_counts.keys(), 0)\n",
        "bar_format=\"{l_bar}/{bar}| {n_fmt}/{total_fmt} [{elapsed} < {remaining}, {rate_fmt}{postfix}]\"\n",
        "\n",
        "print(\"---\", item_counts)\n",
        "with tqdm(\n",
        "    total=len(items),\n",
        "    desc=\"Generating embeddings\",\n",
        "    bar_format=bar_format\n",
        ")as pbar:\n",
        "  for item in items:\n",
        "    item_type = item[\"type\"]\n",
        "    counters[item_type]+=1\n",
        "    if item_type in [\"text\", \"table\"]:\n",
        "      item[\"embedding\"] = generate_multimodal_embedding(prompt=item[\"text\"], output_embedding_length=embedding_vector_dimension)\n",
        "    elif item_type in [\"image\"]:\n",
        "      item[\"embedding\"] = generate_multimodal_embedding(image=item[\"image\"], output_embedding_length=embedding_vector_dimension)\n",
        "\n",
        "  pbar.set_postfix_str(f\"Text: {counters['text']}/{item_counts['text']}, Table: {counters['table']}/{item_counts['table']}, Image: {counters['image']}/{item_counts['image']}\")\n",
        "\n",
        "  pbar.update(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "San3cezq02NI",
        "outputId": "d1be957d-2dac-4c62-a23c-e849828acbf7"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- {'text': 52, 'table': 1, 'image': 26, 'page': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating embeddings:   1%|/▏         | 1/79 [00:15 < 19:49, 15.25s/it, Text: 52/52, Table: 1/1, Image: 26/26]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items[0]"
      ],
      "metadata": {
        "id": "B6Se7mm52r9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_embeddings = all_embeddings = np.array(\n",
        "    [item[\"embedding\"] for item in items if item.get(\"embedding\") is not None],\n",
        "    dtype=\"float32\"\n",
        ")\n",
        "\n",
        "index = faiss.IndexFlatL2(embedding_vector_dimension)\n",
        "index.reset()\n",
        "\n",
        "index.add(np.array(all_embeddings, dtype=np.float32))"
      ],
      "metadata": {
        "id": "sY399Y9t5mCI"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_aws"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef7v8N6O89bf",
        "outputId": "1c4de7ad-9ce9-461b-dcfd-b2299fade0a9"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_aws in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: boto3>=1.40.19 in /usr/local/lib/python3.12/dist-packages (from langchain_aws) (1.41.5)\n",
            "Requirement already satisfied: langchain-core>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_aws) (1.1.0)\n",
            "Requirement already satisfied: numpy<3,>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from langchain_aws) (2.3.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.10.6 in /usr/local/lib/python3.12/dist-packages (from langchain_aws) (2.12.3)\n",
            "Requirement already satisfied: botocore<1.42.0,>=1.41.5 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.40.19->langchain_aws) (1.41.5)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.40.19->langchain_aws) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.16.0,>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.40.19->langchain_aws) (0.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=1.1.0->langchain_aws) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=1.1.0->langchain_aws) (0.4.47)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=1.1.0->langchain_aws) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=1.1.0->langchain_aws) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=1.1.0->langchain_aws) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=1.1.0->langchain_aws) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10.6->langchain_aws) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10.6->langchain_aws) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10.6->langchain_aws) (0.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.42.0,>=1.41.5->boto3>=1.40.19->langchain_aws) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.42.0,>=1.41.5->boto3>=1.40.19->langchain_aws) (2.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=1.1.0->langchain_aws) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.42.0,>=1.41.5->boto3>=1.40.19->langchain_aws) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (3.4.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=1.1.0->langchain_aws) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_aws import ChatBedrock\n",
        "\n",
        "def invoke_nova_multimodal(prompt, matched_items):\n",
        "  system_message = [{\n",
        "      \"text\": \"\"\"You are an helpful assistant for question asnwering,\n",
        "        The text context is relavant information retrieved.\n",
        "        The provided image(s) are relavant information retrieved.\n",
        "        Answer if answer is available in provided context otherwise return no answer found reply\n",
        "      \"\"\"\n",
        "  }]\n",
        "\n",
        "  message_content = []\n",
        "  for item in matched_items:\n",
        "    if item[\"type\"] == \"text\" or item[\"type\"] ==\"table\":\n",
        "      message_content.append({\"text\": item[\"text\"]})\n",
        "    else:\n",
        "      message_content.append({\"image\": item[\"image\"]})\n",
        "\n",
        "    inf_params = {\n",
        "        \"max_new_tokens\" : 300,\n",
        "        \"top_p\":0.9,\n",
        "        \"top_k\":30,\n",
        "    }\n",
        "\n",
        "    message_list = [\n",
        "        {\n",
        "            \"role\":\"user\", \"content\" : message_content\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    native_request = {\n",
        "        \"message\": message_list,\n",
        "        \"system\": system_message,\n",
        "        \"inferenceConfig\": inf_params\n",
        "    }\n",
        "\n",
        "    model_id = \"amazon.nova-pro-v1:0\"\n",
        "    client = ChatBedrock(\n",
        "        model_id=model_id,\n",
        "        aws_access_key_id=YOUR_ACCESS_KEY,\n",
        "        aws_secret_access_key=YOUR_SECRET_KEY,\n",
        "        region_name=\"us-east-1\",\n",
        "        )\n",
        "\n",
        "    response = client.invoke(json.dumps(native_request))\n",
        "\n",
        "    model_response = response.content\n",
        "    return model_response\n",
        "\n"
      ],
      "metadata": {
        "id": "DvFjPlEi7M5y"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the main architecture proposed in the paper?\"\n",
        "query_embedding = generate_multimodal_embedding(prompt=query, output_embedding_length=embedding_vector_dimension)\n",
        "\n",
        "\n",
        "result = index.search(np.array(query_embedding, dtype=np.float32).reshape(1, -1), k=5)\n",
        "\n",
        "print('====',type(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTa52boq9BJT",
        "outputId": "bf74f7a7-aa79-46d2-ca72-91ac38b32a8e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== <class 'tuple'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D, I = result\n",
        "\n",
        "matched_items = [\n",
        "    {k: v for k, v in items[idx].items() if k != \"embedding\"}\n",
        "    for idx in I[0]\n",
        "]\n",
        "print(matched_items)\n",
        "response = invoke_nova_multimodal(query, matched_items)\n",
        "\n",
        "display.Markdown(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "WLRvl1JDEZcu",
        "outputId": "4a0c4a77-ed64-46f6-e033-45aaf1feca44"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'page': 0, 'type': 'text', 'text': 'ity has been considered as a nonclassical feature of quan-\\ntum systems against the classical phase-space distribu-\\ntions, which are always non-negative. However, this dif-\\nfers from other works which deﬁne nonclassicality based\\non the operational formalism wherein preparation, oper-\\nation, and measurement cooperate explicitly [7, 8]. The\\nnonclassicality is identiﬁed by comparing the classical\\npredictions of classical electromagnetism [9] and of the\\nrealistic models [10, 11] assuming physical quantities are\\npredetermined before the actual measurements. There\\nalso have been eﬀorts to employ negative probability as\\ncriteria of describing quantum predictions [12–18].\\nThe quasiprobabilities such as Wigner function and\\ntheir classical counterparts represent a given physical ob-\\nservation in diﬀerent mathematical forms. Furthermore,\\nnegative values in one quasiprobability can be positive\\nin another [8]. These may be regarded as obstacles in', 'path': 'data/text/attention_paper.pdf_text_0_2.txt'}, {'page': 1, 'type': 'text', 'text': 'a quantum system in an operational way, i.e., by account-\\ning for the physical processes in preparing, operating,\\nand measuring a quantum state. We adopt such an op-\\nerational approach in this work, contrary to the conven-\\ntional approach of using mathematical transformations,\\ne.g., Wigner-Weyl transformations, from a quantum state\\nonly. We ﬁnd such a quasiprobability, in particular, satis-\\nfying the commensurability. It was reported that a com-\\nmensurate quasiprobability for a discrete variable system\\ncan be deﬁned in an operational way [15].\\nWe ﬁnd such a quasiprobability distribution for a\\nCV system, calling it an operational quasiprobability\\nfor continuous variables (OQCV). It is deﬁned opera-\\ntionally with sequential and selective measurements in\\nt1\\nt2\\nt1\\nt2\\nt1\\nt2\\nt1\\nt2\\n(a) (m = 0, n = 0)\\n(b) (m 6= 0, n = 0)\\n(c) (m = 0, n 6= 0)\\n(d) (m 6= 0, n 6= 0)\\nˆ%\\nˆ%\\nˆ%\\nˆ%\\nM1\\nM2\\nM1\\nM2\\nFIG. 1. Measurement setups when two observables are con-', 'path': 'data/text/attention_paper.pdf_text_1_2.txt'}, {'page': 6, 'type': 'text', 'text': 'main of NSIT in the limit of an inﬁnite number of average\\nphotons and thus its limit is characterized as classical.\\nWe also propose a feasible optical scheme to realize the\\nsequential measurements of quadrature variables.\\nThe commensurate approach can be extended to the\\nscenarios having more than two temporally (or spa-\\ntially) separated observers sharing quantum systems.\\nWe reported such results for discrete quasiprobability\\nin Ref. [15].\\nIt still remains an open problem to clar-\\nify diﬀerences between the conditions of NSIT and non-\\nnegative OQCV as shown in Fig. 2.\\nACKNOWLEDGMENTS\\nThe authors thank J. Sperling for bringing their at-\\ntention to Ref. [42].\\nThis research was supported by\\nthe National Research Foundation of Korea (NRF) Grant\\nNo. 2014R1A2A1A10050117, funded by the MSIP (Min-\\nistry of Science, ICT and Future Planning), Korean gov-\\nernment.\\nIt was also supported by the MSIP (Min-\\nistry of Science, ICT and Future Planning), Korea, un-', 'path': 'data/text/attention_paper.pdf_text_6_2.txt'}, {'page': 8, 'type': 'text', 'text': 'lishing Company, 1950).\\n[7] R. W. Spekkens, “Contextuality for preparations, trans-\\nformations, and unsharp measurements,” Phys. Rev. A\\n71, 052108 (2005).\\n[8] Christopher Ferrie, “quasiprobability representations of\\nquantum theory with applications to quantum informa-\\ntion science,” Reports on Progress in Physics 74, 116001\\n(2011).\\n[9] Leonard Mandel and Emil Wolf, “Coherence properties of\\noptical ﬁelds,” Rev. Mod. Phys. 37, 231 (1965); L Man-\\ndel, “Non-classical states of the electromagnetic ﬁeld,”\\nPhys. Scr. 1986, 34 (1986).\\n[10] J S Bell, “On the Eistein-Podolsky-Rosen paradox,”\\nPhysics 1, 195-200 (1964).\\n[11] A J Leggett and Anupam Garg, “Quantum mechanics\\nversus macroscopic realism: Is the ﬂux there when no-\\nbody looks?” Phys. Rev. Lett. 54, 857–860 (1985).\\n[12] Robert W. Spekkens, “Negativity and contextuality are\\nequivalent notions of nonclassicality,” Phys. Rev. Lett.\\n101, 020401 (2008).\\n[13] Christopher Ferrie and Joseph Emerson, “Frame repre-', 'path': 'data/text/attention_paper.pdf_text_8_1.txt'}, {'page': 2, 'type': 'text', 'text': 'consider a classical model assuming realism and nonin-\\nvasive measurability. Classical physics has been consid-\\nered as the realistic theory which assumes predetermined\\nphysical quantities before the actual measurements. This\\nimplies the existence of an underlying joint probability\\ndistribution for the outcomes of all possible measure-\\nments.\\nIn a temporal scenario, Leggett and Garg examined\\nnoninvasive measurability at the macroscopic level. One\\ncan measure a physical quantity of a macroscopic object\\nwithout disturbing it. This hypothesis together with re-\\nalism, called macrorealism (MR), leads the Leggett-Garg\\ninequality involving temporal correlations [11]. It shows\\nthat quantum prediction is incompatible with the clas-\\nsical one. More precisely, MR is deﬁned by the follow-\\ning three hypotheses [29, 30]: “Macrorealism per se. A\\nmacroscopic object which has available to it two or more\\nmacroscopically distinct states is at any given time in a', 'path': 'data/text/attention_paper.pdf_text_2_2.txt'}]\n",
            "1------ AKIAQMHLVHQ566HGWXEK\n",
            "2------ UAjRcLLTkSr838zLGY161PM+lqrpftasnt0dh93h\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The text discusses the concept of nonclassicality in quantum systems, particularly in relation to quasiprobabilities like the Wigner function. It highlights that nonclassicality is often identified by comparing classical predictions with quantum predictions, noting that classical phase-space distributions are always non-negative, whereas quantum systems can exhibit negative values in their quasiprobabilities. The text also mentions that different quasiprobabilities can represent the same physical observation in different mathematical forms, and that negative values in one quasiprobability might be positive in another. This variability is seen as an obstacle in defining nonclassicality. \n\nNo specific question is posed in the provided context, so no direct answer can be given. If you have a specific question related to this text, please ask, and I'll do my best to provide an answer based on the context given."
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9y3e0l2ZFww1"
      },
      "execution_count": 86,
      "outputs": []
    }
  ]
}