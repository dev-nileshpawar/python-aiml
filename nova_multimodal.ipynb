{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFTTSn9WXVNYJ44C5xSjfU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dev-nileshpawar/python-aiml/blob/main/nova_multimodal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgIwDPF1VOCQ",
        "outputId": "1820460b-4eaf-4970-e5ca-17b9e47f3dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (1.41.5)\n",
            "Requirement already satisfied: botocore<1.42.0,>=1.41.5 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.41.5)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.16.0,>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from boto3) (0.15.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.42.0,>=1.41.5->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.42.0,>=1.41.5->boto3) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.42.0,>=1.41.5->boto3) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install boto3\n",
        "import boto3\n",
        "import json\n",
        "import base64"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "PRO_MODEL_ID = \"amazon.nova-pro-v1:0\"\n",
        "LITE_MODEL_ID = \"amazon.nova-lite-v1:0\"\n",
        "MACRO_MODEL_ID = \"amazon.nova-macro-v1:0\"\n",
        "\n",
        "YOUR_ACCESS_KEY = userdata.get('YOUR_ACCESS_KEY')\n",
        "YOUR_SECRET_KEY = userdata.get(\"YOUR_SECRET_KEY\")\n",
        "client = boto3.client(\n",
        "    service_name=\"bedrock-runtime\",\n",
        "    region_name=\"us-east-1\",\n",
        "    aws_access_key_id=YOUR_ACCESS_KEY,\n",
        "    aws_secret_access_key=YOUR_SECRET_KEY,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "8qi0X9okVYto"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "system_list = [{\n",
        "    \"text\":\"Act as a creative writing assistant. When the use provides you with topic, write a short story about that topic.\"\n",
        "}]\n",
        "\n",
        "message_list= [{\"role\": \"user\", \"content\":[{\"text\": \"camping trip\"}]}]\n",
        "\n",
        "inf_params = {\"max_new_tokens\": 200, \"top_p\":0.9, \"top_k\":20}\n",
        "\n",
        "request_body = {\n",
        "    \"messages\": message_list,\n",
        "    \"system\": system_list,\n",
        "    \"inferenceConfig\": inf_params\n",
        "}\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "response = client.invoke_model_with_response_stream(modelId = LITE_MODEL_ID, body=json.dumps(request_body))\n",
        "\n",
        "chunk_count = 0\n",
        "time_to_first_token = None\n",
        "\n",
        "\n",
        "stream = response.get('body')\n",
        "if stream:\n",
        "  for event in stream:\n",
        "    chunk = event.get('chunk')\n",
        "    if chunk:\n",
        "      # print the response chunk\n",
        "      chunk_json = json.loads(chunk.get('bytes').decode())\n",
        "      # pretty print json\n",
        "      content_block_delta = chunk_json.get('contentBlockDelta')\n",
        "      if content_block_delta:\n",
        "        if time_to_first_token is None:\n",
        "          time_to_first_token = datetime.now() - start_time\n",
        "          print(f\"Time to first token: {time_to_first_token.total_seconds()} seconds\")\n",
        "\n",
        "        chunk_count+=1\n",
        "        current_time = datetime.now()\n",
        "        elapsed_time = current_time - start_time\n",
        "        # print(f\"Time elapsed: {elapsed_time.total_seconds()} seconds\")\n",
        "        print(content_block_delta.get('delta').get(\"text\"), end=\"\")\n",
        "        # print(f\"Total Chunks: {chunk_count}\")\n",
        "\n",
        "else:\n",
        "  print(\"No response received\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh9cfR8FVwyH",
        "outputId": "2b158edf-5073-4221-c9b0-76bf0782dec4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to first token: 0.901164 seconds\n",
            "The sun hung low in the sky, casting a golden hue over the dense forest as the Johnson family arrived at Pinewood Campground. Excitement buzzed in the air, mingling with the scent of pine and the distant sound of a babbling brook. \n",
            "\n",
            "\"Alright, everyone! Let's set up camp!\" Dad called, his voice filled with enthusiasm. \n",
            "\n",
            "Mom began unpacking the tent, while little sister Mia dashed off to explore the surroundings. She giggled as she skipped over fallen logs and peered into the underbrush, her imagination running wild with thoughts of fairies and hidden treasures.\n",
            "\n",
            "Dad and older brother Jake took charge of gathering firewood, their laughter echoing through the trees as they stacked branches into a neat pile. The crackling fire soon roared to life, sending sparks dancing into the twilight.\n",
            "\n",
            "As the stars began to twinkle overhead, the family gathered around the campfire. Dad told stories of his own childhood camping trips, his eyes twinkling with nostalgia. Mia listened wide-eyed, her imagination painting vivid pictures of the"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Synchronous API**"
      ],
      "metadata": {
        "id": "J1NAcR8eFhpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_list = [{\"text\": \"You should respond all messages in French\"}]\n",
        "\n",
        "message_list = [{\"role\": \"user\", \"content\":[{\"text\":\"Freecodecamp is a great platform to learn coding and technology in the field of computer science\"}]}]\n",
        "\n",
        "inf_params = {\"max_new_tokens\": 300, \"top_p\":0.9, \"top_k\":20}\n",
        "\n",
        "native_request = {\n",
        "    \"messages\": message_list,\n",
        "    \"system\": system_list,\n",
        "    \"inferenceConfig\": inf_params\n",
        "}\n",
        "\n",
        "response = client.invoke_model(modelId=LITE_MODEL_ID, body=json.dumps(native_request))\n",
        "\n",
        "request_id = response[\"ResponseMetadata\"][\"RequestId\"]\n",
        "print(f\"Request ID: {request_id}\")\n",
        "\n",
        "model_response = json.loads(response[\"body\"].read())\n",
        "print(json.dumps(model_response, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAIt8Vqd5zad",
        "outputId": "51a888ca-a918-43ba-975b-b55fbc09e10f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request ID: fed76cb0-affa-42f0-8d84-eef0bc778b97\n",
            "{\n",
            "  \"output\": {\n",
            "    \"message\": {\n",
            "      \"content\": [\n",
            "        {\n",
            "          \"text\": \"Freecodecamp est une excellente plateforme pour apprendre la programmation et la technologie dans le domaine de l'informatique. Elle offre une vari\\u00e9t\\u00e9 de cours gratuits et interactifs qui couvrent divers langages de programmation, frameworks et technologies. Que vous soyez d\\u00e9butant ou que vous cherchiez \\u00e0 approfondir vos comp\\u00e9tences, Freecodecamp propose des ressources p\\u00e9dagogiques adapt\\u00e9es \\u00e0 tous les niveaux. De plus, la communaut\\u00e9 active et les d\\u00e9fis pratiques aident \\u00e0 consolider les connaissances acquises.\"\n",
            "        }\n",
            "      ],\n",
            "      \"role\": \"assistant\"\n",
            "    }\n",
            "  },\n",
            "  \"stopReason\": \"end_turn\",\n",
            "  \"usage\": {\n",
            "    \"inputTokens\": 25,\n",
            "    \"outputTokens\": 118,\n",
            "    \"totalTokens\": 143,\n",
            "    \"cacheReadInputTokenCount\": 0,\n",
            "    \"cacheWriteInputTokenCount\": 0\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Streaming API Call**"
      ],
      "metadata": {
        "id": "Y27OwbnXHGUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "system_list = [{\n",
        "    \"text\": \"Act as a creative assistannt. When the user provides you with a topic, write a short story about the topic.\"\n",
        "}]\n",
        "\n",
        "message_list = [{\n",
        "    \"role\":\"user\", \"content\" :[{\"text\": \"A camping trip\"}]\n",
        "}]\n",
        "\n",
        "inf_params = {\"max_new_tokens\": 200, \"top_p\": 0.9, \"top_k\": 20}\n",
        "\n",
        "request_body = {\n",
        "    \"messages\":message_list,\n",
        "    \"system\": system_list,\n",
        "    \"inferenceConfig\": inf_params\n",
        "}\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "response = client.invoke_model_with_response_stream(\n",
        "    modelId=LITE_MODEL_ID, body=json.dumps(request_body)\n",
        ")\n",
        "\n",
        "chunk_count = 0;\n",
        "\n",
        "time_to_first_token = None\n",
        "\n",
        "stream = response.get(\"body\")\n",
        "if stream:\n",
        "  for event in stream:\n",
        "    chunk = event.get(\"chunk\")\n",
        "    if chunk:\n",
        "      chunk_json = json.loads(chunk.get(\"bytes\").decode())\n",
        "      content_block_delta = chunk_json.get(\"contentBlockDelta\")\n",
        "      if content_block_delta:\n",
        "        if time_to_first_token is None:\n",
        "          time_to_first_token = datetime.now() - start_time\n",
        "          print(f\"Time to first token: {time_to_first_token.total_seconds()} seconds\")\n",
        "        else:\n",
        "          print(content_block_delta.get(\"delta\").get(\"text\"), end=\"\")\n",
        "  print(f\"\\n\\n Total chunks: {chunk_count}\")\n",
        "\n",
        "else:\n",
        "  print(\"No response stream received\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIH0ArtvHM1v",
        "outputId": "27703ba2-7c0e-451f-da0e-1ec1cb0e923b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to first token: 0.402233 seconds\n",
            " sun was just beginning to rise over the horizon, casting a warm golden glow over the forest as a group of friends set out on their camping trip. They had been planning this adventure for weeks, and now that the day had finally arrived, excitement buzzed in the air.\n",
            "\n",
            "At the forefront of the group was Jake, the self-appointed leader of the expedition. He had packed the camping gear meticulously, ensuring that they had everything they needed for a comfortable stay in the great outdoors. His friends admired his thoroughness, knowing that his preparation would make the trip all the more enjoyable.\n",
            "\n",
            "As they hiked deeper into the forest, the sounds of civilization faded away, replaced by the symphony of nature. Birds chirped melodiously, and the rustling of leaves underfoot created a soothing backdrop to their journey. The friends couldn't help but feel a sense of camaraderie as they walked side by side, sharing stories and laughter.\n",
            "\n",
            "After a couple of hours, they arrived at their chosen campsite, a clearing by\n",
            "\n",
            " Total chunks: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0s10uOhZNBGg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Understanding\n",
        "\n",
        "Amazon Nova model allows to include multiple images in the payload with a max size of 25 MB, Amazon Nova models can analyze the passed images and answer questions, classify an image as well as summarize images based on provided instructions.\n",
        "\n",
        "## Image size information\n",
        "To provide the best possible results, amazon Nova automatically rescales input images up or down depending on their apsect ratio and original resolution, for each image, amazon nova first identifies aspect ratio first from 1:1, 1:2, 1:3, 1:4, 1:5, 1:6, 1:7, 1:8, 1:9, 2:3, 2:4 and their transposes. Then the image is rescaled so that at least one side of the image is greater than 896px or the length of shorter side of the original image, while maintaining the closest apsect ratio, there is a max resoultion 8000x8000 pixels.\n",
        "\n",
        "| Image resolution | 900 x 450 | 900 x 900 | 1400 x 900 | 1.8k x 900 | 1.3k x 1.3k |\n",
        "|--------|--------|-------- |-------- |-------- |-------- |\n",
        "| Estimated token count | ~800 | ~1300 | ~1800 | ~2400 | ~2600 |\n"
      ],
      "metadata": {
        "id": "ydL78uA_Nf17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./Snow-Transparent-File.png\", \"rb\") as snow_image_file:\n",
        "  snow_image_bytes = snow_image_file.read()\n",
        "  base_64_encoded_data = base64.b64encode(snow_image_bytes)\n",
        "  snow_base64_string = base_64_encoded_data.decode(\"utf-8\")\n",
        "\n",
        "with open(\"./desert.jpg\", \"rb\") as desert_image_file:\n",
        "  desert_image_bytes = desert_image_file.read()\n",
        "  desert_base_64_encoded_data = base64.b64encode(desert_image_bytes)\n",
        "  desert_base64_string = desert_base_64_encoded_data.decode(\"utf-8\")\n",
        "\n",
        "\n",
        "  system_list = [{\n",
        "    \"text\": \"You are an expter artist, when the user provides you with an image(s), Generate 3 separate art titles for EACH image individually. Clearly mention which title belongs to which image.\"\n",
        "  }]\n",
        "  message_list = [{\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [{\n",
        "          \"image\" : {\n",
        "              \"format\": \"png\",\n",
        "              \"source\": {\n",
        "                  \"bytes\": snow_base64_string\n",
        "              }\n",
        "          },\n",
        "        }, {\n",
        "            \"image\": {\n",
        "                \"format\": \"jpg\",\n",
        "                \"source\": {\n",
        "                    \"bytes\" : desert_base64_string\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        {\"text\":\"Provide an art title for all these image(s)\"}\n",
        "      ]\n",
        "  }]\n",
        "\n",
        "  inf_params = {\"max_new_tokens\": 300, \"top_p\": 0.1, \"top_k\": 20, \"temperature\": 0.3}\n",
        "\n",
        "  native_request = {\n",
        "      \"messages\": message_list,\n",
        "      \"system\": system_list,\n",
        "      \"inferenceConfig\": inf_params\n",
        "  }\n",
        "\n",
        "  response = client.invoke_model(\n",
        "      modelId=PRO_MODEL_ID, body=json.dumps(native_request)\n",
        "  )\n",
        "\n",
        "  model_response = json.loads(response[\"body\"].read())\n",
        "  print(model_response[\"output\"][\"message\"][\"content\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI39W69VXlyX",
        "outputId": "e2449eb8-ac41-481a-e4c2-07376109a6d0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Image 1: Snowy Landscape**\n",
            "1. \"Winter's Embrace\"\n",
            "2. \"Frosted Pines\"\n",
            "3. \"Snowfall Symphony\"\n",
            "\n",
            "**Image 2: Desert Palms**\n",
            "1. \"Oasis Mirage\"\n",
            "2. \"Desert Solitude\"\n",
            "3. \"Golden Dunes\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wCaPVdQyZKb-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jCGGIe3sYmWk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Video Understanding**"
      ],
      "metadata": {
        "id": "UUsbmfe2gh3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./mov_bbb.mp4\", \"rb\") as video_file:\n",
        "  video_bytes = video_file.read()\n",
        "  video_base64_encoded_data = base64.b64encode(video_bytes)\n",
        "  video_base64_string = video_base64_encoded_data.decode(\"utf-8\")\n",
        "\n",
        "system_list = [{\n",
        "    \"text\": \"You are an expert media analyst. When the user provides you with a video, provide a summary of the video.\"\n",
        "}]\n",
        "\n",
        "message_list = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\":[{\n",
        "        \"video\": {\n",
        "            \"format\": \"mp4\",\n",
        "            \"source\": {\n",
        "                \"bytes\": video_base64_string\n",
        "            }\n",
        "        }\n",
        "    }, {\n",
        "        \"text\": \"Provide summary for this clip\"\n",
        "    }]\n",
        "}]\n",
        "\n",
        "inf_params = {\"max_new_tokens\": 500, \"top_p\": 0.1, \"top_k\": 20, \"temperature\": 0.3}\n",
        "\n",
        "\n",
        "native_request = {\n",
        "    \"messages\": message_list,\n",
        "    \"system\": system_list,\n",
        "    \"inferenceConfig\": inf_params\n",
        "}\n",
        "\n",
        "response = client.invoke_model(modelId=PRO_MODEL_ID, body=json.dumps(native_request))\n",
        "\n",
        "model_response = json.loads(response[\"body\"].read())\n",
        "print(model_response[\"output\"][\"message\"][\"content\"][0][\"text\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "F-vJ3sdQYogq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc4ca66-0b76-41be-d4f0-d5fcb1034909"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The video features a white rabbit in a grassy field. Initially, the rabbit is standing still, and a butterfly flies around it. Then, the rabbit starts running, and the butterfly continues to fly around it. Eventually, the rabbit stops running and stands still again in the grassy field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIHKW24yTss4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Video from S3"
      ],
      "metadata": {
        "id": "_lrzv6CrV9HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_list = [{\n",
        "    \"text\": \"You are an expert media analyst. When the user provides you with a video, provide a summary of the video.\"\n",
        "}]\n",
        "\n",
        "message_list = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\":[{\n",
        "        \"video\": {\n",
        "            \"format\": \"mp4\",\n",
        "            \"source\": {\n",
        "                \"s3Location\": {\n",
        "                    \"uri\": \"s3://npawar868bucketupload/mov_bbb.mp4\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }, {\n",
        "        \"text\": \"Provide summary for this clip\"\n",
        "    }]\n",
        "}]\n",
        "\n",
        "inf_params = {\"max_new_tokens\": 500, \"top_p\": 0.1, \"top_k\": 20, \"temperature\": 0.3}\n",
        "\n",
        "\n",
        "native_request = {\n",
        "    \"messages\": message_list,\n",
        "    \"system\": system_list,\n",
        "    \"inferenceConfig\": inf_params\n",
        "}\n",
        "\n",
        "response = client.invoke_model(modelId=PRO_MODEL_ID, body=json.dumps(native_request))\n",
        "\n",
        "model_response = json.loads(response[\"body\"].read())\n",
        "print(model_response[\"output\"][\"message\"][\"content\"][0][\"text\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhYasJPvWALM",
        "outputId": "21f92518-c8a2-4159-844e-5b11b35a5a72"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The video features a white rabbit in a grassy field. Initially, the rabbit is standing still, and a butterfly flies around it. Then, the rabbit starts running, and the butterfly continues to fly around it. Eventually, the rabbit stops running and stands still again in the grassy field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y5NbnCv5WQfh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}